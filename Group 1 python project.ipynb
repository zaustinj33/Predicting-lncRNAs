{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group 1 Python project\n",
    "### Identification of all lncRNAs in Arabidopsis\n",
    "### By Group 1 : Zac, Jiang, Xiaolin, and Alaina \n",
    "### Formatting, integration credit: Zac\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0.1 - import modules; define file input, output locations\n",
    "### Credit: all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import myGTF\n",
    "from operator import itemgetter \n",
    "from Bio.SeqIO.FastaIO import SimpleFastaParser\n",
    "from Bio.Data import CodonTable\n",
    "\n",
    "#WorkDir = input() # for custom folder in\n",
    "#WorkDir = \"/groups/ALS5224/Group1/PythonProject/\"\n",
    "WorkDir = \"/home/zacjohnson/OneDrive/School-dj-Ubuntu/DataScience/PythonProjectData/\"\n",
    "os.chdir(WorkDir)\n",
    "\n",
    "# Input\n",
    "GTF = WorkDir + \"GTF.gtf\"\n",
    "RawSequence = WorkDir + \"Ath.fa\"\n",
    "\n",
    "# Intermediates\n",
    "TranscriptSeq = WorkDir + \"transcriptSeq.fasta\"\n",
    "TranslatedORF = WorkDir + \"translatedORF.fa\"\n",
    "ProteinFASTA = WorkDir + \"proteinFASTA.fa\"\n",
    "\n",
    "# Output\n",
    "lncRNA = WorkDir + \"lncRNA.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0.2 - Import GTF file, parse raw FASTA sequence for all exons\n",
    "#### Output: transcriptSeq.fa\n",
    "#### Credit: Song Li, modifications by Zac and Jiang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pt 154478\n",
      "Mt 366924\n",
      "4 18585056\n",
      "2 19698289\n",
      "3 23459830\n",
      "5 26975502\n",
      "1 30427671\n"
     ]
    }
   ],
   "source": [
    "## Import GTF file, create TS start/stop positions\n",
    "ts2pos = {}   \n",
    "ts2chr = {}\n",
    "for k in myGTF.lines('large.gtf'): \n",
    "    tsid = k['transcript_id']; chrname = k['seqname']\n",
    "    tsstart = int(k['start']); tsend = int(k['end'])\n",
    "\n",
    "    if not tsid in ts2pos: \n",
    "        ts2pos[tsid]=[]    \n",
    "        ts2pos[tsid].append([tsstart,tsend]) \n",
    "    else:\n",
    "        ts2pos[tsid].append([tsstart,tsend])\n",
    "\n",
    "    if not tsid in ts2chr:\n",
    "        ts2chr[tsid]=chrname\n",
    "\n",
    "# Create sorted dictionary of start/stop positions\n",
    "ts2pos_s = {}\n",
    "for ets in ts2pos:\n",
    "    ts2pos_s[ets]=sorted(ts2pos[ets], key = itemgetter(1)) \n",
    "    \n",
    "# Parse raw sequence file for start/stop positions\n",
    "chr2seq = {}\n",
    "for seq_record in SeqIO.parse(RawSequence, \"fasta\"):\n",
    "    chr2seq[seq_record.id] = seq_record.seq \n",
    "    print(seq_record.id, len(seq_record))\n",
    "\n",
    "# Write exons in raw sequence file to new dictionary    \n",
    "ts2seq = {}\n",
    "for eachts in ts2chr:\n",
    "    tschr = ts2chr[eachts]        \n",
    "    exonpos = ts2pos_s[eachts]\n",
    "    chrseq = chr2seq[tschr]\n",
    "    tmpseq = ''\n",
    "    for eachexon in exonpos:\n",
    "        exonstart = eachexon[0]\n",
    "        exonend = eachexon[1]\n",
    "        exonseq = chrseq[exonstart-1:exonend] \n",
    "        if tmpseq == '':               \n",
    "            tmpseq = exonseq           \n",
    "        else:                          \n",
    "            tmpseq = tmpseq + exonseq  \n",
    "    ts2seq[eachts] = tmpseq\n",
    "\n",
    "# Write exons to new file with fasta formatting\n",
    "with open(\"transcriptSeq.fasta\", \"w\") as ofile:\n",
    "    for i in ts2seq:\n",
    "        ofile.write(\">\" + i + \"\\n\" +str(ts2seq[i]) + \"\\n\")\n",
    "ofile.close()\n",
    "\n",
    "print(\"Step 0 finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Define ORF locations as nucleotide fasta\n",
    "#### Output: translateORF.fa\n",
    "#### Credit: https://github.com/zkstewart, implemented by Jiang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to run a terminal command to use biopython_orf_find.py in chdir\n",
    "# Removed 'True' tag, was giving error\n",
    "#to run a terminal command to use biopython_orf_find.py, result saved in 'translatedORF.fa'\n",
    "#the biopython_orf_find.py is modified from https://github.com/zkstewart/orf-finder-py\n",
    "#the modification is that I removed the ORF without stop codons(line 368 to line371)\n",
    "#-min is the minimum length of the found protein\n",
    "#-max is the maximum length of the found protein\n",
    "#-st is the format of output(nucleotide/protein)\n",
    "#-num is the number of protein translated per transcript(if multiple, sorted from long to short, if 1, only the longest)\n",
    "#-f is force write/replace file with same name\n",
    "#-n doesn't change the fasta header\n",
    "os.system('python3 biopython_orf_find.py -i transcriptSeq.fasta  -o translatedORF.fa -min 1 -max 10000 -st PROT -num 1 -f Y -n')  \n",
    "print(\"Step 1 finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Create Protein FASTA file from Gene FASTA file\n",
    "#### Credit Xianlin\n",
    "#### (currently not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"standard_table = CodonTable.unambiguous_dna_by_name[\"Standard\"]\n",
    "Geneseq = {} #create an empty directory\n",
    "for record in SeqIO.parse(TranscriptORF,\"fasta\"):\n",
    "    Geneseq[record.id] = record.seq  \n",
    "\n",
    "pfa = open(proteinFASTA, \"w\")\n",
    "    \n",
    "for i in Geneseq.items():\n",
    "    header = i[0]\n",
    "    seq = i[1]\n",
    "    (seqorf,longestorf) = longestorffinder(seq)\n",
    "    aaseqlen = longestorf/3-1\n",
    "    aaseq = seqorf.translate(standard_table)\n",
    "    pfa.write(\">\"+header+\";\"+str(aaseqlen)+\"\\n\"+str(aaseq)+\"\\n\")\n",
    "pfa.close()\n",
    "\n",
    "Print(\"Step 2 finished\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Create transcript list from Protein Fasta file\n",
    "#### Credit: Jiang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "orfDic = {}\n",
    "transcriptDic = {}\n",
    "longer_than_200 = []\n",
    "orf_shorter_than_100 = []\n",
    "prolen = []\n",
    "\n",
    "# Find all ORFs > 200 nucleotides long\n",
    "for record in SeqIO.parse(TranscriptSeq,'fasta'):\n",
    "    transcriptDic[record.id] = record.seq\n",
    "    if len(record.seq) > 200:\n",
    "        longer_than_200.append(record.id)\n",
    "        \n",
    "# Find all ORFs < 100aa long\n",
    "for record in SeqIO.parse(TranslatedORF,'fasta'):\n",
    "    orfDic[record.id] = record.seq\n",
    "    if len(record.seq) < 100:\n",
    "        orf_shorter_than_100.append(record.id)\n",
    "\n",
    "orfKeyList = orfDic.keys()\n",
    "transcriptKeyList = transcriptDic.keys()\n",
    "\n",
    "## lncRNA is longer than 200nt, has no orf or orf is shorter than 100 aa\n",
    "seqNoOrf = set(transcriptKeyList) - set(orfKeyList)\n",
    "lncRNA = set(longer_than_200) & set(orf_shorter_than_100) | seqNoOrf \n",
    "\n",
    "#get protein length, if no orf, protein length is set to 0\n",
    "for i in transcriptKeyList:\n",
    "    if i in orfKeyList:\n",
    "        prolen.append(len(orfDic[i]))\n",
    "    else:\n",
    "        prolen.append(0)\n",
    "\n",
    "lncrna_bool = []\n",
    "for i in transcriptKeyList:\n",
    "    if i in lncRNA:\n",
    "        lncrna_bool.append('YES')\n",
    "    else:\n",
    "        lncrna_bool.append('NO')\n",
    "\n",
    "print(\"Step 3 finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Find lncRNAs and length of longest ORF < 100 amino acids\n",
    "#### Credit: Zac And Alaina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TranscriptID  ProLen IslncRNA\n",
      "3   TCONS_00000004      23      YES\n",
      "32  TCONS_00000033      84      YES\n",
      "34  TCONS_00000035      78      YES\n",
      "38  TCONS_00000039      72      YES\n",
      "68  TCONS_00000069       0      YES\n",
      "                  0  1\n",
      "561  TCONS_00005562  3\n",
      "676  TCONS_00007097  3\n",
      "670  TCONS_00007067  3\n",
      "15   TCONS_00000199  3\n",
      "435  TCONS_00004068  3\n",
      "Step 4 finished\n"
     ]
    }
   ],
   "source": [
    "## Define TCs that are lncRNA - Zac\n",
    "columns_title_lncRNA = ['TranscriptID', 'ProLen', 'IslncRNA']\n",
    "data = list(zip(transcriptKeyList, prolen, lncrna_bool))\n",
    "df = pd.DataFrame(data, columns=columns_title_lncRNA) # Create dataframe of all transcripts\n",
    "Data_YesOnly = df.loc[df.IslncRNA == \"YES\"]\n",
    "with open(lncRNA, \"w\") as lnc: # Write lncRNA transcripts only\n",
    "    Data_YesOnly.to_csv(lnc)\n",
    "lncRNA_Only.close()\n",
    "print(Data_YesOnly.head())\n",
    "\n",
    "## Getting length of ORFs - Alaina\n",
    "FastaFile = open(TranslatedORF, 'r')\n",
    "LenFile = open('gene_lengths.csv', 'w')\n",
    "\n",
    "for name, seq in SimpleFastaParser(FastaFile):\n",
    "    seqLen = len(seq)\n",
    "    LenFile.write(name + ',' + str(seqLen) + '\\n')\n",
    "\n",
    "FastaFile.close()\n",
    "LenFile.close()\n",
    "\n",
    "columns_title = ['TranscriptID', 'ProLen']\n",
    "gene2length = {}\n",
    "output1 = open(\"gene_100aa_less.txt\",\"w\")\n",
    "output2 = open(\"gene_100aa_less_sorted.txt\",\"w\")\n",
    "with open(\"gene_lengths.csv\", 'r') as input1: \n",
    "\n",
    "    for i in input1.readlines():\n",
    "        line = i.rstrip()\n",
    "        fields = line.split(\",\")\n",
    "        gene = fields[0]\n",
    "        length = int(fields[1])\n",
    "        gene2length[gene] = length\n",
    "        if gene2length[gene] < 100:\n",
    "            keep = [gene, str(gene2length[gene])]\n",
    "            keep_gene = gene\n",
    "            keep_length = str(gene2length[gene])\n",
    "            output1.write(keep_gene + \"\\t\" + keep_length + \"\\n\")\n",
    "\n",
    "with open(\"gene_100aa_less.txt\",\"r\") as input2:\n",
    "    sorting_table = pd.read_table(input2, header = None)\n",
    "    lengths_sorted = sorting_table.sort_values(1)\n",
    "    print(lengths_sorted.head())\n",
    "    lengths_csv = lengths_sorted.to_csv(header = None)\n",
    "    output2.write(lengths_csv)\n",
    "input1.close()\n",
    "input2.close()\n",
    "\n",
    "print(\"Step 4 finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
