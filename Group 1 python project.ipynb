{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification of all lncRNAs in Arabidopsis\n",
    "### By Group 1 : Jiang, Zac, Xianlin, and Alaina \n",
    "### Formatting, integration credit: Zac\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0.1 - import modules; define file input, output locations\n",
    "### Credit: all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import myGTF\n",
    "from operator import itemgetter \n",
    "from Bio.SeqIO.FastaIO import SimpleFastaParser\n",
    "from Bio.Data import CodonTable\n",
    "import operator\n",
    "\n",
    "#WorkDir = input() # for custom folder input\n",
    "#WorkDir = \"/groups/ALS5224/Group1/PythonProject/\"\n",
    "WorkDir = \"/home/zacjohnson/OneDrive/School-dj-Ubuntu/DataScience/ProjectDataTest/\"\n",
    "os.chdir(WorkDir)\n",
    "\n",
    "# Input\n",
    "GTF = WorkDir + \"GTF.gtf\"\n",
    "RawSequence = WorkDir + \"Ath.fa\"\n",
    "\n",
    "# Intermediates\n",
    "TranscriptSeq = WorkDir + \"transcriptSeq.fasta\"\n",
    "TranslatedORF = WorkDir + \"translatedORF.fasta\"\n",
    "LongestORF = WorkDir + \"longestORF.fasta\"\n",
    "\n",
    "# Output\n",
    "lncRNAcsv = WorkDir + \"lncRNA.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0.2 - Import GTF file, parse raw FASTA sequence for all exons\n",
    "#### Output: transcriptSeq.fa\n",
    "#### Credit: Song Li, modifications by Zac and Jiang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pt 154478\n",
      "Mt 366924\n",
      "4 18585056\n",
      "2 19698289\n",
      "3 23459830\n",
      "5 26975502\n",
      "1 30427671\n",
      "Step 0 finished\n"
     ]
    }
   ],
   "source": [
    "## Import GTF file, create TS start/stop positions\n",
    "ts2pos = {}   \n",
    "ts2chr = {}\n",
    "for k in myGTF.lines('large.gtf'): \n",
    "    tsid = k['transcript_id']; chrname = k['seqname']\n",
    "    tsstart = int(k['start']); tsend = int(k['end'])\n",
    "\n",
    "    if not tsid in ts2pos: \n",
    "        ts2pos[tsid]=[]    \n",
    "        ts2pos[tsid].append([tsstart,tsend]) \n",
    "    else:\n",
    "        ts2pos[tsid].append([tsstart,tsend])\n",
    "\n",
    "    if not tsid in ts2chr:\n",
    "        ts2chr[tsid]=chrname\n",
    "\n",
    "# Create sorted dictionary of start/stop positions\n",
    "ts2pos_s = {}\n",
    "for ets in ts2pos:\n",
    "    ts2pos_s[ets]=sorted(ts2pos[ets], key = itemgetter(1)) \n",
    "    \n",
    "# Parse raw sequence file for start/stop positions\n",
    "chr2seq = {}\n",
    "for seq_record in SeqIO.parse(RawSequence, \"fasta\"):\n",
    "    chr2seq[seq_record.id] = seq_record.seq \n",
    "    print(seq_record.id, len(seq_record))\n",
    "\n",
    "# Write exons in raw sequence file to new dictionary    \n",
    "ts2seq = {}\n",
    "for eachts in ts2chr:\n",
    "    tschr = ts2chr[eachts]        \n",
    "    exonpos = ts2pos_s[eachts]\n",
    "    chrseq = chr2seq[tschr]\n",
    "    tmpseq = ''\n",
    "    for eachexon in exonpos:\n",
    "        exonstart = eachexon[0]\n",
    "        exonend = eachexon[1]\n",
    "        exonseq = chrseq[exonstart-1:exonend] \n",
    "        if tmpseq == '':               \n",
    "            tmpseq = exonseq           \n",
    "        else:                          \n",
    "            tmpseq = tmpseq + exonseq  \n",
    "    ts2seq[eachts] = tmpseq\n",
    "\n",
    "# Write exons to new file with fasta formatting\n",
    "with open(\"transcriptSeq.fasta\", \"w\") as ofile:\n",
    "    for i in ts2seq:\n",
    "        ofile.write(\">\" + i + \"\\n\" +str(ts2seq[i]) + \"\\n\")\n",
    "ofile.close()\n",
    "\n",
    "print(\"Step 0 finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Define ORF locations as nucleotide fasta\n",
    "#### Output: translateORF.fa\n",
    "#### Credit: https://github.com/zkstewart, implemented by Jiang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 finished\n"
     ]
    }
   ],
   "source": [
    "# to run a terminal command to use biopython_orf_find.py in chdir\n",
    "# Removed 'True' tag, was giving error\n",
    "#to run a terminal command to use biopython_orf_find.py, result saved in 'translatedORF.fa'\n",
    "#the biopython_orf_find.py is modified from https://github.com/zkstewart/orf-finder-py\n",
    "#the modification is that I removed the ORF without stop codons(line 368 to line371)\n",
    "#-min is the minimum length of the found protein\n",
    "#-max is the maximum length of the found protein\n",
    "#-st is the format of output(nucleotide/protein)\n",
    "# NUCL = nucleotide, PROT = Protein, BOTH = both\n",
    "#-num is the number of protein translated per transcript(if multiple, sorted from long to short, if 1, only the longest)\n",
    "#-f is force write/replace file with same name\n",
    "#-n doesn't change the fasta header\n",
    "\n",
    "os.system('python3 biopython_orf_find.py -i transcriptSeq.fasta  -o longestORF.fasta -min 1 -max 10000 -st NUCL -num 1 -f Y -n')\n",
    "print(\"Step 1 finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Create Protein FASTA file from Gene FASTA file\n",
    "#### Credit Xianlin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2 finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Use standard table to translate gene sequence into protein sequence\n",
    "from Bio.Data import CodonTable\n",
    "standard_table = CodonTable.unambiguous_dna_by_name[\"Standard\"]\n",
    "\n",
    "Geneseq = {} #create an empty directory\n",
    "for record in SeqIO.parse(LongestORF,\"fasta\"):\n",
    "    Geneseq[record.id] = record.seq.translate(standard_table)\n",
    "\n",
    "proseq = open(TranslatedORF, \"w\")\n",
    "for i in Geneseq:\n",
    "    proseq.write(\">\"+i+'\\n'+str(Geneseq[i]).rstrip(\"*\")+'\\n')\n",
    "proseq.close()\n",
    "\n",
    "print(\"Step 2 finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Create transcript list from Protein Fasta file\n",
    "#### Credit: Jiang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3 finished\n"
     ]
    }
   ],
   "source": [
    "orfDic = {}\n",
    "transcriptDic = {}\n",
    "longer_than_200 = []\n",
    "orf_shorter_than_100 = []\n",
    "prolen = []\n",
    "\n",
    "# Find all ORFs > 200 nucleotides long\n",
    "for record in SeqIO.parse(TranscriptSeq,'fasta'):\n",
    "    transcriptDic[record.id] = record.seq\n",
    "    if len(record.seq) > 200:\n",
    "        longer_than_200.append(record.id)\n",
    "        \n",
    "# Find all ORFs < 100aa long\n",
    "for record in SeqIO.parse(TranslatedORF,'fasta'):\n",
    "    orfDic[record.id] = record.seq\n",
    "    if len(record.seq) < 100:\n",
    "        orf_shorter_than_100.append(record.id)\n",
    "\n",
    "orfKeyList = orfDic.keys()\n",
    "transcriptKeyList = transcriptDic.keys()\n",
    "\n",
    "## lncRNA is longer than 200nt, has no orf or orf is shorter than 100 aa\n",
    "seqNoOrf = set(transcriptKeyList) - set(orfKeyList)\n",
    "lncRNA = set(longer_than_200) & set(orf_shorter_than_100) | seqNoOrf \n",
    "\n",
    "#get protein length, if no orf, protein length is set to 0\n",
    "for i in transcriptKeyList:\n",
    "    if i in orfKeyList:\n",
    "        prolen.append(len(orfDic[i]))\n",
    "    else:\n",
    "        prolen.append(0)\n",
    "\n",
    "lncrna_bool = []\n",
    "for i in transcriptKeyList:\n",
    "    if i in lncRNA:\n",
    "        lncrna_bool.append('YES')\n",
    "    else:\n",
    "        lncrna_bool.append('NO')\n",
    "\n",
    "print(\"Step 3 finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Find lncRNAs and length of longest ORF < 100 amino acids\n",
    "#### Credit: Alaina and Zac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0  1\n",
      "438  TCONS_00004068  2\n",
      "568  TCONS_00005562  2\n",
      "677  TCONS_00007067  2\n",
      "683  TCONS_00007097  2\n",
      "15   TCONS_00000199  2\n",
      "                  0   1\n",
      "787  TCONS_00008078  99\n",
      "830  TCONS_00008283  99\n",
      "344  TCONS_00003257  99\n",
      "748  TCONS_00007920  99\n",
      "65   TCONS_00000842  99\n",
      "522  TCONS_00005026  99\n",
      "29   TCONS_00000429  99\n",
      "511  TCONS_00004797  99\n",
      "512  TCONS_00004798  99\n",
      "691  TCONS_00007156  99\n",
      "Step 4 finished\n"
     ]
    }
   ],
   "source": [
    "## Getting length of ORFs - Alaina\n",
    "FastaFile = open(TranslatedORF, 'r')\n",
    "LenFile = open('gene_lengths.csv', 'w')\n",
    "\n",
    "for name, seq in SimpleFastaParser(FastaFile):\n",
    "    seqLen = len(seq)\n",
    "    LenFile.write(name + ',' + str(seqLen) + '\\n')\n",
    "\n",
    "FastaFile.close()\n",
    "LenFile.close()\n",
    "\n",
    "columns_title = ['TranscriptID', 'ProLen']\n",
    "gene2length = {}\n",
    "output1 = open(\"gene_100aa_less.txt\",\"w\")\n",
    "output2 = open(\"gene_100aa_less_sorted.txt\",\"w\")\n",
    "with open(\"gene_lengths.csv\", 'r') as input1: \n",
    "\n",
    "    for i in input1.readlines():\n",
    "        line = i.rstrip()\n",
    "        fields = line.split(\",\")\n",
    "        gene = fields[0]\n",
    "        length = int(fields[1])\n",
    "        gene2length[gene] = length\n",
    "        if gene2length[gene] < 100:\n",
    "            keep = [gene, str(gene2length[gene])]\n",
    "            keep_gene = gene\n",
    "            keep_length = str(gene2length[gene])\n",
    "            output1.write(keep_gene + \"\\t\" + keep_length + \"\\n\")\n",
    "\n",
    "with open(\"gene_100aa_less.txt\",\"r\") as input2:\n",
    "    sorting_table = pd.read_table(input2, header = None)\n",
    "    lengths_sorted = sorting_table.sort_values(1)\n",
    "    print(lengths_sorted.head())\n",
    "    print(lengths_sorted.nlargest(10,1))\n",
    "    lengths_csv = lengths_sorted.to_csv(header = None)\n",
    "    output2.write(lengths_csv)\n",
    "input1.close()\n",
    "input2.close()\n",
    "\n",
    "print(\"Step 4 finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.1 Define lncRNAs\n",
    "#### Credit Jiang and Zac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TranscriptID  ProLen IslncRNA\n",
      "3   TCONS_00000004      22      YES\n",
      "32  TCONS_00000033      83      YES\n",
      "34  TCONS_00000035      77      YES\n",
      "38  TCONS_00000039      71      YES\n",
      "68  TCONS_00000069       0      YES\n",
      "The following transcript is the longest lncRNA: \n",
      "TCONS_00003043 TGAATTCCTTTTCATCTTTATTTTTTAGAATGGTCCAACTCCAACCAAGTCATTTCTTTTTAAACAATCTTTGTTTTGCTTTTTGAAAATTCGTCCATAGACTCACTGTCATGGGTTAATATAAGTTGTATGTGCAAAATTACTATACTCTAATATTTACTTAGGCAATAATATGATAAATCTCTGAAAATACTCTTTTGGTTCGTGAACATTTGGTATTTTTTTTATAATAATGTTATTGTGTAAATTAGCCTGGAACAATAATTATATTTGTTTACTAGTTATATTAGACAAAATAACCTGTTATCGAAAACAAAATTTCTCCCAATGGTCAACATATCCTTGCGATGGACGAAATGATGTCAAACAGTTTTTTCGAATAATTTCATATAATATTCAAAAAAAAAAGAAGTTGTTTTTTCCAATCAGGTAGTCTTAAACAAATCTGCAACATAAGTTATATGTTTTAAAAAATATACTCTATGGTTATTTGGGTTATATTCATCAATCGGTAGGTCAGTCCATGACAACGTACTCTAAATTATTAGGAGCAAAATCATGATCTAGTTTAATAAACGGTCTAAACAGACTAATTTTTTTTTTCTGGGAATAAGATAGGGTTAGACCACATGGATAATATGCATGTCCAAATTCTTTAAAATCTAAGCCTTAAAATTTGTTGATAATCAGAATTCTTTTCTATGTCTCTTGTAGAACAAAATGTCAAATTATAAGTATATAAAGAAGCTTAAGTACAACTGATATTCGTAGAGTTATAAATGTCAAAGGTTGTATTTTTTTTATAGCCCACTATATATATGTTGATTAAGTTTTGAAAACGATATATTTTTTTTTGTGTTTTTCCGCTTTCACATACTGGAATTGTTGAAAGATTGTGGATTAGAGAAAAATGTAAGTTATTTAAAAAAAAATACCGAAAAAATTGGTGTACAATAGAGAATTTGTACAAATGAGGTTTTCAATGCACATATTAAATTTGATTGTATAAGATAGTTTGGAGTTGGTTAGTAAAGATCTGGATAAAATCAGGGATTATGTTACATATGTGCAGGGGTCTAAGTCTAGAGAAAACATGTTTCAAAACTGTACGAAAACAGTTGGCATTCAAGTTAAAAAAAAATCTGATTTTAAATGTCACAACTTAGAGTGTTAGTTGTCTCATTGAGAACTGCAAAAAACAAACTAATATTATGCTCTGTAGAATTTGTTATGTTCATCTTCTCTATGTTCTTGAATTGTATCCAATGTTTAATGAACCAGTCATGGACAAGCATATTATGAAGCGGGCATTAAATGGTCATTGTCGTTAACGAACATGGGCTTTAACGGACTGGACGTGATGGATATGAGCGGCCCAATGGTCATAAAATATTAGGATAAGTGATTTGGGGCAAAATAGAAAAACACTAATCGTCGAAAAATATTTCTTGGTTTCTCCGACAGTCTGGCGATTACTTTGGCGATTACTTCTTTCTCCGGCGAATTCCCTTCAACATCTTGTCTCCATCACATCATGGCTTCTCCGAAGATTCCTAATCCAGTTAGTTCGATTCAAGTTTGCAATAACTAGTGTTCGATAACTAGGTTTTGCAATTCAAGGTTTTTTCGATTTCAATTTAAGATCCTACGATTTTGAAAGAGACCCATTTTCTTTTGTTTAAGATCATAGATGAAGTTCCTGGTAGGTTCTGTTTAACAACAGATCTTTGGAGATCATTTACAATATAGGGCTACATGTGTTTGACTGCACATTATATCGAATTCGAAGACGAAGATTCTGTCATTTTGTGCATTCCCTATTCCACATACTGGTTTTGTTATAGCCACAAAGGTCTTGGCATTGTTAAAAGAGTGGGGGATAGAAAAGAGAGTGTTTACTATCACAGTCGATAATGCATCATCAAATGACAATATGCAAGGACTCCTCAATTTCAATCCATTTGAGTCTTAACGCAAATGTATTTTTCTGTTGTACTTAAGTGATCTTATTGAGTTCGTTAATGAAGACAAAGATGGCAAGGGAGAAGAAGAAGAAGTTTAAATTTGCTTTCAATTTGCTTTTGGATTTGATACTTTGTTGAATACTTGAATTGTGTTTAAACTTGCTTTAGATTTAATACTTTGTTGTTTAAATTTGCTTTGGATTTAATACTTTGTTGTTTAAATTTGCTTCGTTGAATACTTGAATTGTGATATTTTCAAAGTATTAGACTTCATACTTATGTATTGATTGAAATATGAATCAAAAACTATTTGTGTTCAAATTTGGTTCTTTTCTGACTATAAATATGATATTTATATATGGTTAATACACTACTTTGTATATAAAAATAATAAATTATGTTATGATTCTTATACTGATCATATCTCAGAGGTGTTATTTTAAATTTTCTCATAATACTAGTATTAATAGATAATCACCATTAGACACATATTTGGATGAGCCAATGTTCAATATGGTTACATTTAGAAGTTTGAATGTAGTGGCATATTAGAAAGACAATTCAAGTCGTTTTACAGAGTTAGCGCCTATGGCATATAATGTTTGTATCCATATCACAATTGTGGCCTCAAAATTATCCTTTAGAATAGGTAAATGTGTTCCTAAGAAATTAAGATTTTTCCTCTTACTAAGACATATGGAACATCAACAATGAACCGCCATCTAACACTTTGCCCTGAAATGTTTTAGTGAAGTTAGACTTAAGTATGATCATAAAGTTGACCGAGAGATGACTCCTGAGATAATCATATATCATGATTTGCCTTTTCGATATGTTGAATATGAAAAGGTTAGGGCTAGAGATAAATTTCTAAACCCGGACTGTCAGCTTATATGTAGACAAACAGCTGCAATTGATGTTTTCAAGAGATATGAGATAGAGAACCTTAAGTTGATAGATGTTTTGGCTAAACACAATGGTCGGATGTGTTTAACATCAGATTTATGGTCATCGCGGGATACGATGACGAGATATATTTGTGTAACTTCCCACCATATTGATAAATCATGATGGCTAAACAATAAAATATTAGCTATTTTGTAATCTTAAGCCTCCACATAATGGTAGAAATATTTGTAAGAAAATTTATGATTGCTTGAAGGAATGTGGTTTAGAGAAAAACATACTTACTATCACACTGGATAATGCTTCTGTAACAAAAGAATGCAAACTATTCTTAAGTATCGTCTTCAGAGTCGTATCAGGTTGTTGTGTGGAGAAAGTTTTTGCATGTGAGGTGTTATGCACATGTGTTGAAACTGATAGTACAAGCAGTGTTAGAATTAACGACTAGCCTGTTGGAGAATATTAGAGAGTGTCAAGTTTGTAAAAGCAAGTGAGTCAAGAAAAATTCTTTTACATTATGCATAGAGAGTGTAGGGATCAAGAGTCGAACTATGTTATCTCTAAATATCACAACTCGTTGGAATTCTAGATATGAAATGCTAGTTAGAGCTTTGAAGTTGAGAAAAGCATTTGCTAGTTTGAATTTGTATGAAAGAGGTTCAGTTTTTTACCTATAGAAGAAGAGTGAGATCGTGGAGAGAAAATTGTGACCTCTTGAAGCCTTTTAATACCATCACTATATACTTTTCAGGAGTGAAATATCCTACGCACTACAAGAAAAAGGTTAATTCCAACCGACATATTAGTTGGTAATTTGTAAGAATTATATGTCTCCAATATTGCTTTCAATATCACGTATATTTGTTGGAATATGATCGTTGGAAATTTGCATTTGTCGCAAATTTATTGGAAACGTTTATATCGAGTAAATGATATGGCCAATTCGTTGGATACTTCTGATAATTTATTTGTTGGACATTTGTTGGAATTCACTGTGAAGTTTCTAACAAATTGTTCTAACATATACTTTGTAATTGTGAAAAATTGAGTTGTTGCTTAAGAAGAATGTTAATTGTAATGATGTTGATGTAAGAGAAATGGCTAAGAAGATGCAAAAGAAGTTTCTTAAGTATTTGGATCAATATAGTGTTATTCTAGCTATGGGGGATGCCTTAGATCCGAGACTAAAACTGAAGATACTTAGGCCAACTTATGACAAAGTGGATCCCATTACTGCTGAGGAGAAGGTTGCTATAGTGAGGAAAAATCTGAATTCCGCTTTATGAAGAATATCAAACTATATCTGCAAGTTCTTCAAAGTCTTCAACCACACTTACTCTACACGAGCTTCTTAGTGAATCACCACTTAAAGAAGATGTGAATGATGTAAGTATAACAATATATTTGAATATCTTTCACTAGTTCTCGTTTGATTTATCTTGTGTGTATTTGTATATTCACAGGATCTTTTTGAGCTTGAATGTGACCTCATATCTGCTTCAAAAAATACCAAGTCAACTTTGGAAATCTATTTAGGTGATGAACCAAGACTAGAGATGAAGACTTTCTCTGACATGAAAATCTTAAGCTTTTGCAAAGAGAATCAACATATGTGTGGTGATTTAATTTCAATGGCATCTGATTTATTTAGCATCACAATCACCATAGTAGCATCTGAGACTCGGGTTTTAGTGTTGGAGGCCGGATGTTAAATACTTTTAAAAATGGCCTTCTTCCCCAATATGTGCAAGCATTACTTTGCACTCGCAATTGGCTACGTGGATATGCAGAGCTTTGAAGGTAAAATTGCAGTATTAAATTATTAACTAATGTGAATTATTCTCTTGAACTAACTTATATCATTAAATTGTAGGAGACATCGAAGAAATTTTTGATG 4767\n"
     ]
    }
   ],
   "source": [
    "## Define TCs that are lncRNA \n",
    "columns_title_lncRNA = ['TranscriptID', 'ProLen', 'IslncRNA']\n",
    "data = list(zip(transcriptKeyList, prolen, lncrna_bool))\n",
    "df = pd.DataFrame(data, columns=columns_title_lncRNA) # Create dataframe of all transcripts\n",
    "Data_YesOnly = df.loc[df.IslncRNA == \"YES\"]\n",
    "\n",
    "\n",
    "with open(lncRNAcsv, \"w\") as lnc: # Write lncRNA transcripts only to csv\n",
    "    Data_YesOnly.to_csv(lnc)\n",
    "lncRNA_Only.close()\n",
    "print(Data_YesOnly.head())\n",
    "\n",
    "\n",
    "lncRNAlen = {}\n",
    "for i in transcriptDic:\n",
    "   if i in lncRNA:\n",
    "       lncRNAlen[i] = len(transcriptDic[i])\n",
    "lncMAX = max(lncRNAlen.items(), key=operator.itemgetter(1))[0]\n",
    "\n",
    "print(\"The following transcript is the longest lncRNA: \")\n",
    "print(lncMAX,transcriptDic[lncMAX],lncRNAlen[lncMAX])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
